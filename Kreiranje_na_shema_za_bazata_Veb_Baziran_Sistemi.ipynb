{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marijaklisarovska/graphdb-dashboard-app/blob/master/Kreiranje_na_shema_za_bazata_Veb_Baziran_Sistemi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3mnPcQhL99vf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HappinessDataProcessor:\n",
        "    def __init__(self):\n",
        "        self.standardized_data = {}\n",
        "        self.region_mapping = {}\n",
        "        self.metric_columns = [\n",
        "            'gdp_per_capita', 'social_support', 'healthy_life_expectancy',\n",
        "            'freedom_to_make_life_choices', 'generosity', 'perceptions_of_corruption'\n",
        "        ]\n",
        "\n",
        "    def load_and_standardize_data(self) -> Dict:\n",
        "\n",
        "        column_mappings = {\n",
        "            '2015': {\n",
        "                'Country': 'country',\n",
        "                'Region': 'region',\n",
        "                'Happiness Rank': 'happiness_rank',\n",
        "                'Happiness Score': 'happiness_score',\n",
        "                'Economy (GDP per Capita)': 'gdp_per_capita',\n",
        "                'Family': 'social_support',\n",
        "                'Health (Life Expectancy)': 'healthy_life_expectancy',\n",
        "                'Freedom': 'freedom_to_make_life_choices',\n",
        "                'Trust (Government Corruption)': 'perceptions_of_corruption',\n",
        "                'Generosity': 'generosity',\n",
        "                'Dystopia Residual': 'dystopia_residual'\n",
        "            },\n",
        "            '2016': {\n",
        "                'Country': 'country',\n",
        "                'Region': 'region',\n",
        "                'Happiness Rank': 'happiness_rank',\n",
        "                'Happiness Score': 'happiness_score',\n",
        "                'Economy (GDP per Capita)': 'gdp_per_capita',\n",
        "                'Family': 'social_support',\n",
        "                'Health (Life Expectancy)': 'healthy_life_expectancy',\n",
        "                'Freedom': 'freedom_to_make_life_choices',\n",
        "                'Trust (Government Corruption)': 'perceptions_of_corruption',\n",
        "                'Generosity': 'generosity',\n",
        "                'Dystopia Residual': 'dystopia_residual'\n",
        "            },\n",
        "            '2017': {\n",
        "                'Country': 'country',\n",
        "                'Happiness.Rank': 'happiness_rank',\n",
        "                'Happiness.Score': 'happiness_score',\n",
        "                'Economy..GDP.per.Capita.': 'gdp_per_capita',\n",
        "                'Family': 'social_support',\n",
        "                'Health..Life.Expectancy.': 'healthy_life_expectancy',\n",
        "                'Freedom': 'freedom_to_make_life_choices',\n",
        "                'Trust..Government.Corruption.': 'perceptions_of_corruption',\n",
        "                'Generosity': 'generosity',\n",
        "                'Dystopia.Residual': 'dystopia_residual'\n",
        "            },\n",
        "            '2018': {\n",
        "                'Country or region': 'country',\n",
        "                'Overall rank': 'happiness_rank',\n",
        "                'Score': 'happiness_score',\n",
        "                'GDP per capita': 'gdp_per_capita',\n",
        "                'Social support': 'social_support',\n",
        "                'Healthy life expectancy': 'healthy_life_expectancy',\n",
        "                'Freedom to make life choices': 'freedom_to_make_life_choices',\n",
        "                'Generosity': 'generosity',\n",
        "                'Perceptions of corruption': 'perceptions_of_corruption'\n",
        "            },\n",
        "            '2019': {\n",
        "                'Country or region': 'country',\n",
        "                'Overall rank': 'happiness_rank',\n",
        "                'Score': 'happiness_score',\n",
        "                'GDP per capita': 'gdp_per_capita',\n",
        "                'Social support': 'social_support',\n",
        "                'Healthy life expectancy': 'healthy_life_expectancy',\n",
        "                'Freedom to make life choices': 'freedom_to_make_life_choices',\n",
        "                'Generosity': 'generosity',\n",
        "                'Perceptions of corruption': 'perceptions_of_corruption'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        years = ['2015', '2016', '2017', '2018', '2019']\n",
        "\n",
        "        for year in years:\n",
        "            df = pd.read_csv(f'{year}.csv')\n",
        "            df.columns = df.columns.str.strip()\n",
        "            df = df.rename(columns=column_mappings[year])\n",
        "            df['year'] = int(year)\n",
        "\n",
        "            df = df.fillna(0)\n",
        "\n",
        "            df['happiness_tier'] = df['happiness_rank'].apply(self._get_happiness_tier)\n",
        "\n",
        "            for metric in self.metric_columns:\n",
        "                if metric in df.columns:\n",
        "                    df[f'{metric}_level'] = df[metric].apply(self._get_performance_level)\n",
        "\n",
        "            self.standardized_data[year] = df\n",
        "            print(f\"Loaded {year}: {len(df)} countries\")\n",
        "\n",
        "        return self.standardized_data\n",
        "\n",
        "    def _get_happiness_tier(self, rank: int) -> str:\n",
        "        if rank <= 10:\n",
        "            return \"Top_10\"\n",
        "        elif rank <= 25:\n",
        "            return \"Top_25\"\n",
        "        elif rank <= 50:\n",
        "            return \"Top_50\"\n",
        "        elif rank <= 100:\n",
        "            return \"Top_100\"\n",
        "        else:\n",
        "            return \"Bottom_Tier\"\n",
        "\n",
        "    def _get_performance_level(self, value: float) -> str:\n",
        "        if pd.isna(value) or value == 0:\n",
        "            return \"No_Data\"\n",
        "        elif value >= 1.0:\n",
        "            return \"High\"\n",
        "        elif value >= 0.5:\n",
        "            return \"Medium\"\n",
        "        else:\n",
        "            return \"Low\"\n",
        "\n",
        "    def build_region_mapping(self):\n",
        "        df_2015 = self.standardized_data['2015']\n",
        "\n",
        "        for _, row in df_2015.iterrows():\n",
        "            self.region_mapping[row['country']] = row['region']\n",
        "\n",
        "        df_2016 = self.standardized_data['2016']\n",
        "        for _, row in df_2016.iterrows():\n",
        "            if row['country'] not in self.region_mapping:\n",
        "                self.region_mapping[row['country']] = row['region']\n",
        "\n",
        "        print(f\"Built region mapping for {len(self.region_mapping)} countries\")\n",
        "        return self.region_mapping\n",
        "\n",
        "    def calculate_regional_averages(self) -> Dict:\n",
        "        regional_averages = {}\n",
        "\n",
        "        for year, df in self.standardized_data.items():\n",
        "            if 'region' not in df.columns:\n",
        "                df['region'] = df['country'].map(self.region_mapping)\n",
        "\n",
        "            regional_averages[year] = {}\n",
        "\n",
        "            for region in df['region'].dropna().unique():\n",
        "                region_data = df[df['region'] == region]\n",
        "                regional_averages[year][region] = {}\n",
        "\n",
        "                regional_averages[year][region]['happiness_score'] = region_data['happiness_score'].mean()\n",
        "\n",
        "                for metric in self.metric_columns:\n",
        "                    if metric in region_data.columns:\n",
        "                        regional_averages[year][region][metric] = region_data[metric].mean()\n",
        "\n",
        "        return regional_averages\n",
        "\n",
        "    def find_similar_countries(self, threshold: float = 0.3) -> List[Tuple]:\n",
        "        similar_pairs = []\n",
        "\n",
        "        for year, df in self.standardized_data.items():\n",
        "            countries = df['country'].tolist()\n",
        "\n",
        "            for i, country1 in enumerate(countries):\n",
        "                for country2 in countries[i+1:]:\n",
        "                    row1 = df[df['country'] == country1].iloc[0]\n",
        "                    row2 = df[df['country'] == country2].iloc[0]\n",
        "\n",
        "                    score_diff = abs(row1['happiness_score'] - row2['happiness_score'])\n",
        "\n",
        "                    if score_diff <= threshold:\n",
        "                        similar_pairs.append((country1, country2, year, score_diff))\n",
        "\n",
        "        return similar_pairs\n",
        "\n",
        "    def find_year_over_year_changes(self) -> List[Dict]:\n",
        "        changes = []\n",
        "        years = ['2015', '2016', '2017', '2018', '2019']\n",
        "\n",
        "        for i in range(len(years) - 1):\n",
        "            year1, year2 = years[i], years[i + 1]\n",
        "            df1, df2 = self.standardized_data[year1], self.standardized_data[year2]\n",
        "\n",
        "            merged = df1[['country', 'happiness_score', 'happiness_rank']].merge(\n",
        "                df2[['country', 'happiness_score', 'happiness_rank']],\n",
        "                on='country', suffixes=('_prev', '_curr')\n",
        "            )\n",
        "\n",
        "            merged['score_change'] = merged['happiness_score_curr'] - merged['happiness_score_prev']\n",
        "            merged['rank_change'] = merged['happiness_rank_prev'] - merged['happiness_rank_curr']\n",
        "\n",
        "            for _, row in merged.iterrows():\n",
        "                changes.append({\n",
        "                    'country': row['country'],\n",
        "                    'from_year': year1,\n",
        "                    'to_year': year2,\n",
        "                    'score_change': row['score_change'],\n",
        "                    'rank_change': row['rank_change'],\n",
        "                    'change_type': 'improvement' if row['score_change'] > 0.1 else 'decline' if row['score_change'] < -0.1 else 'stable'\n",
        "                })\n",
        "\n",
        "        return changes\n",
        "\n",
        "    def identify_metric_leaders_laggards(self) -> Dict:\n",
        "        leaders_laggards = {\n",
        "            'leaders': {},\n",
        "            'laggards': {}\n",
        "        }\n",
        "\n",
        "        for year, df in self.standardized_data.items():\n",
        "            leaders_laggards['leaders'][year] = {}\n",
        "            leaders_laggards['laggards'][year] = {}\n",
        "\n",
        "            for metric in self.metric_columns:\n",
        "                if metric in df.columns:\n",
        "                    metric_data = df[df[metric] > 0].copy()\n",
        "\n",
        "                    if len(metric_data) > 0:\n",
        "                        top_10_percent = int(len(metric_data) * 0.1)\n",
        "                        leaders = metric_data.nlargest(max(1, top_10_percent), metric)['country'].tolist()\n",
        "\n",
        "                        bottom_10_percent = int(len(metric_data) * 0.1)\n",
        "                        laggards = metric_data.nsmallest(max(1, bottom_10_percent), metric)['country'].tolist()\n",
        "\n",
        "                        leaders_laggards['leaders'][year][metric] = leaders\n",
        "                        leaders_laggards['laggards'][year][metric] = laggards\n",
        "\n",
        "        return leaders_laggards\n",
        "\n",
        "    def get_comprehensive_stats(self) -> Dict:\n",
        "        stats = {\n",
        "            'countries': len(self.get_all_countries()),\n",
        "            'regions': len(self.get_all_regions()),\n",
        "            'years': len(self.standardized_data),\n",
        "            'metrics': len(self.metric_columns),\n",
        "            'total_data_points': sum(len(df) for df in self.standardized_data.values())\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def get_all_countries(self) -> List[str]:\n",
        "        all_countries = set()\n",
        "        for year_data in self.standardized_data.values():\n",
        "            all_countries.update(year_data['country'].tolist())\n",
        "        return sorted(list(all_countries))\n",
        "\n",
        "    def get_all_regions(self) -> List[str]:\n",
        "        return sorted(list(set(self.region_mapping.values())))"
      ],
      "metadata": {
        "id": "NKH_2tjuR0Zl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = HappinessDataProcessor()\n",
        "standardized_data = processor.load_and_standardize_data()\n",
        "region_mapping = processor.build_region_mapping()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rliXMXofSuRt",
        "outputId": "12d62c38-f61f-4f98-db53-e76e4fbae458"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2015: 158 countries\n",
            "Loaded 2016: 157 countries\n",
            "Loaded 2017: 155 countries\n",
            "Loaded 2018: 156 countries\n",
            "Loaded 2019: 156 countries\n",
            "Built region mapping for 164 countries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regional_averages = processor.calculate_regional_averages()\n",
        "similar_countries = processor.find_similar_countries()\n",
        "year_changes = processor.find_year_over_year_changes()\n",
        "leaders_laggards = processor.identify_metric_leaders_laggards()"
      ],
      "metadata": {
        "id": "5GNAoi8dTEVF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats = processor.get_comprehensive_stats()\n",
        "\n",
        "for key, value in stats.items():\n",
        "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "print(f\"\\nSimilar country pairs found: {len(similar_countries)}\")\n",
        "print(f\"Year-over-year changes tracked: {len(year_changes)}\")\n",
        "print(\"Sample similar countries:\", similar_countries[:3])\n",
        "print(\"Sample improvements:\", [c for c in year_changes if c['change_type'] == 'improvement'][:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC3s4cuRTYVf",
        "outputId": "943b424f-140c-4587-edb9-07a010cbc004"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Countries: 170\n",
            "Regions: 10\n",
            "Years: 5\n",
            "Metrics: 6\n",
            "Total Data Points: 782\n",
            "\n",
            "Similar country pairs found: 8659\n",
            "Year-over-year changes tracked: 604\n",
            "Sample similar countries: [('Switzerland', 'Iceland', '2015', np.float64(0.0259999999999998)), ('Switzerland', 'Denmark', '2015', np.float64(0.05999999999999961)), ('Switzerland', 'Norway', '2015', np.float64(0.0649999999999995))]\n",
            "Sample improvements: [{'country': 'Germany', 'from_year': '2015', 'to_year': '2016', 'score_change': 0.24399999999999977, 'rank_change': 10, 'change_type': 'improvement'}, {'country': 'Malta', 'from_year': '2015', 'to_year': '2016', 'score_change': 0.18600000000000083, 'rank_change': 7, 'change_type': 'improvement'}, {'country': 'Guatemala', 'from_year': '2015', 'to_year': '2016', 'score_change': 0.20099999999999962, 'rank_change': 4, 'change_type': 'improvement'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j\n",
        "from neo4j import GraphDatabase\n",
        "import pandas as pd\n",
        "from typing import Dict, List"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yliq8uH6T-nu",
        "outputId": "0179b977-ba91-4268-f14e-ba1cc75e9277"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neo4j\n",
            "  Downloading neo4j-5.28.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from neo4j) (2025.2)\n",
            "Downloading neo4j-5.28.2-py3-none-any.whl (313 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/313.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/313.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: neo4j\n",
            "Successfully installed neo4j-5.28.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HappinessGraphBuilder:\n",
        "    def __init__(self, uri: str, username: str, password: str):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def clear_database(self):\n",
        "        with self.driver.session() as session:\n",
        "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
        "            print(\"Database cleared\")\n",
        "\n",
        "    def create_constraints_and_indexes(self):\n",
        "        constraints_queries = [\n",
        "            \"CREATE CONSTRAINT country_name IF NOT EXISTS FOR (c:Country) REQUIRE c.name IS UNIQUE\",\n",
        "            \"CREATE CONSTRAINT region_name IF NOT EXISTS FOR (r:Region) REQUIRE r.name IS UNIQUE\",\n",
        "            \"CREATE CONSTRAINT year_value IF NOT EXISTS FOR (y:Year) REQUIRE y.year IS UNIQUE\",\n",
        "            \"CREATE CONSTRAINT metric_name IF NOT EXISTS FOR (m:MetricCategory) REQUIRE m.name IS UNIQUE\",\n",
        "            \"CREATE CONSTRAINT tier_name IF NOT EXISTS FOR (t:HappinessTier) REQUIRE t.name IS UNIQUE\",\n",
        "            \"CREATE CONSTRAINT level_name IF NOT EXISTS FOR (l:PerformanceLevel) REQUIRE l.name IS UNIQUE\"\n",
        "        ]\n",
        "\n",
        "        index_queries = [\n",
        "            \"CREATE INDEX country_happiness_score IF NOT EXISTS FOR (c:Country) ON (c.happiness_score)\",\n",
        "            \"CREATE INDEX country_happiness_rank IF NOT EXISTS FOR (c:Country) ON (c.happiness_rank)\"\n",
        "        ]\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            for query in constraints_queries + index_queries:\n",
        "                try:\n",
        "                    session.run(query)\n",
        "                    print(f\"✓ Created: {query.split()[1]} {query.split()[2]}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"✗ Failed: {e}\")\n",
        "\n",
        "    def create_base_nodes(self, processor):\n",
        "        with self.driver.session() as session:\n",
        "            countries = processor.get_all_countries()\n",
        "            for country in countries:\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (c:Country {name: $country})\n",
        "                \"\"\", country=country)\n",
        "            print(f\"Created {len(countries)} Country nodes\")\n",
        "\n",
        "            regions = processor.get_all_regions()\n",
        "            for region in regions:\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (r:Region {name: $region})\n",
        "                \"\"\", region=region)\n",
        "            print(f\"Created {len(regions)} Region nodes\")\n",
        "\n",
        "            years = [2015, 2016, 2017, 2018, 2019]\n",
        "            for year in years:\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (y:Year {year: $year})\n",
        "                \"\"\", year=year)\n",
        "            print(f\"Created {len(years)} Year nodes\")\n",
        "\n",
        "            metrics = [\n",
        "                'GDP_per_Capita', 'Social_Support', 'Healthy_Life_Expectancy',\n",
        "                'Freedom_to_Make_Life_Choices', 'Generosity', 'Perceptions_of_Corruption'\n",
        "            ]\n",
        "            for metric in metrics:\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (m:MetricCategory {name: $metric})\n",
        "                \"\"\", metric=metric)\n",
        "            print(f\"Created {len(metrics)} MetricCategory nodes\")\n",
        "\n",
        "            tiers = ['Top_10', 'Top_25', 'Top_50', 'Top_100', 'Bottom_Tier']\n",
        "            for tier in tiers:\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (t:HappinessTier {name: $tier})\n",
        "                \"\"\", tier=tier)\n",
        "            print(f\"Created {len(tiers)} HappinessTier nodes\")\n",
        "\n",
        "            levels = ['High', 'Medium', 'Low', 'No_Data']\n",
        "            for level in levels:\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (l:PerformanceLevel {name: $level})\n",
        "                \"\"\", level=level)\n",
        "            print(f\"Created {len(levels)} PerformanceLevel nodes\")\n",
        "\n",
        "    def create_country_region_relationships(self, region_mapping):\n",
        "        with self.driver.session() as session:\n",
        "            for country, region in region_mapping.items():\n",
        "                session.run(\"\"\"\n",
        "                    MATCH (c:Country {name: $country})\n",
        "                    MATCH (r:Region {name: $region})\n",
        "                    MERGE (c)-[:BELONGS_TO]->(r)\n",
        "                \"\"\", country=country, region=region)\n",
        "            print(f\"Created {len(region_mapping)} BELONGS_TO relationships\")\n",
        "\n",
        "    def create_happiness_data_relationships(self, standardized_data):\n",
        "        with self.driver.session() as session:\n",
        "            for year, df in standardized_data.items():\n",
        "                for _, row in df.iterrows():\n",
        "                    session.run(\"\"\"\n",
        "                        MATCH (c:Country {name: $country})\n",
        "                        MATCH (y:Year {year: $year})\n",
        "                        MERGE (c)-[:HAS_HAPPINESS_DATA {\n",
        "                            year: $year,\n",
        "                            happiness_score: $score,\n",
        "                            happiness_rank: $rank,\n",
        "                            gdp_per_capita: $gdp,\n",
        "                            social_support: $social,\n",
        "                            healthy_life_expectancy: $life,\n",
        "                            freedom_to_make_life_choices: $freedom,\n",
        "                            generosity: $generosity,\n",
        "                            perceptions_of_corruption: $corruption\n",
        "                        }]->(y)\n",
        "                    \"\"\",\n",
        "                        country=row['country'],\n",
        "                        year=int(year),\n",
        "                        score=float(row['happiness_score']),\n",
        "                        rank=int(row['happiness_rank']),\n",
        "                        gdp=float(row.get('gdp_per_capita', 0)),\n",
        "                        social=float(row.get('social_support', 0)),\n",
        "                        life=float(row.get('healthy_life_expectancy', 0)),\n",
        "                        freedom=float(row.get('freedom_to_make_life_choices', 0)),\n",
        "                        generosity=float(row.get('generosity', 0)),\n",
        "                        corruption=float(row.get('perceptions_of_corruption', 0))\n",
        "                    )\n",
        "                print(f\"Created {len(df)} HAS_HAPPINESS_DATA relationships for {year}\")\n",
        "\n",
        "    def create_tier_relationships(self, standardized_data):\n",
        "        with self.driver.session() as session:\n",
        "            for year, df in standardized_data.items():\n",
        "                for _, row in df.iterrows():\n",
        "                    session.run(\"\"\"\n",
        "                        MATCH (c:Country {name: $country})\n",
        "                        MATCH (t:HappinessTier {name: $tier})\n",
        "                        MERGE (c)-[:BELONGS_TO_TIER {year: $year}]->(t)\n",
        "                    \"\"\",\n",
        "                        country=row['country'],\n",
        "                        tier=row['happiness_tier'],\n",
        "                        year=int(year)\n",
        "                    )\n",
        "                print(f\"Created tier relationships for {year}\")\n",
        "\n",
        "    def create_metric_performance_relationships(self, leaders_laggards, standardized_data):\n",
        "        with self.driver.session() as session:\n",
        "            metric_mapping = {\n",
        "                'gdp_per_capita': 'GDP_per_Capita',\n",
        "                'social_support': 'Social_Support',\n",
        "                'healthy_life_expectancy': 'Healthy_Life_Expectancy',\n",
        "                'freedom_to_make_life_choices': 'Freedom_to_Make_Life_Choices',\n",
        "                'generosity': 'Generosity',\n",
        "                'perceptions_of_corruption': 'Perceptions_of_Corruption'\n",
        "            }\n",
        "\n",
        "            for year, metrics in leaders_laggards['leaders'].items():\n",
        "                for metric, countries in metrics.items():\n",
        "                    metric_name = metric_mapping[metric]\n",
        "                    for country in countries:\n",
        "                        df = standardized_data[year]\n",
        "                        country_data = df[df['country'] == country]\n",
        "                        if not country_data.empty:\n",
        "                            value = float(country_data[metric].iloc[0])\n",
        "                            session.run(\"\"\"\n",
        "                                MATCH (c:Country {name: $country})\n",
        "                                MATCH (m:MetricCategory {name: $metric})\n",
        "                                MERGE (c)-[:EXCELS_IN {\n",
        "                                    year: $year,\n",
        "                                    value: $value,\n",
        "                                    percentile: 'top_10'\n",
        "                                }]->(m)\n",
        "                            \"\"\", country=country, metric=metric_name, year=int(year), value=value)\n",
        "\n",
        "                print(f\"Created EXCELS_IN relationships for {year}\")\n",
        "\n",
        "            for year, metrics in leaders_laggards['laggards'].items():\n",
        "                for metric, countries in metrics.items():\n",
        "                    metric_name = metric_mapping[metric]\n",
        "                    for country in countries:\n",
        "                        df = standardized_data[year]\n",
        "                        country_data = df[df['country'] == country]\n",
        "                        if not country_data.empty:\n",
        "                            value = float(country_data[metric].iloc[0])\n",
        "                            session.run(\"\"\"\n",
        "                                MATCH (c:Country {name: $country})\n",
        "                                MATCH (m:MetricCategory {name: $metric})\n",
        "                                MERGE (c)-[:STRUGGLES_WITH {\n",
        "                                    year: $year,\n",
        "                                    value: $value,\n",
        "                                    percentile: 'bottom_10'\n",
        "                                }]->(m)\n",
        "                            \"\"\", country=country, metric=metric_name, year=int(year), value=value)\n",
        "\n",
        "                print(f\"Created STRUGGLES_WITH relationships for {year}\")\n",
        "\n",
        "    def create_similarity_relationships(self, similar_countries):\n",
        "        if not similar_countries:\n",
        "            print(\"No similar countries found, skipping similarity relationships\")\n",
        "            return\n",
        "\n",
        "        limited_pairs = similar_countries[:500]\n",
        "        print(f\"Creating similarity relationships for {len(limited_pairs)} pairs (limited from {len(similar_countries)} for performance)\")\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            batch_size = 50\n",
        "            total_batches = (len(limited_pairs) + batch_size - 1) // batch_size\n",
        "\n",
        "            for i in range(0, len(limited_pairs), batch_size):\n",
        "                batch = limited_pairs[i:i + batch_size]\n",
        "                batch_num = (i // batch_size) + 1\n",
        "\n",
        "                with session.begin_transaction() as tx:\n",
        "                    for country1, country2, year, score_diff in batch:\n",
        "                        tx.run(\"\"\"\n",
        "                            MATCH (c1:Country {name: $country1})\n",
        "                            MATCH (c2:Country {name: $country2})\n",
        "                            MERGE (c1)-[:SIMILAR_TO {\n",
        "                                year: $year,\n",
        "                                score_difference: $score_diff,\n",
        "                                similarity_threshold: 0.2\n",
        "                            }]->(c2)\n",
        "                        \"\"\",\n",
        "                            country1=country1,\n",
        "                            country2=country2,\n",
        "                            year=int(year),\n",
        "                            score_diff=float(score_diff)\n",
        "                        )\n",
        "\n",
        "                print(f\"Batch {batch_num}/{total_batches} complete ({len(batch)} relationships)\")\n",
        "\n",
        "            print(f\"Created {len(limited_pairs)} SIMILAR_TO relationships\")\n",
        "\n",
        "    def create_temporal_change_relationships(self, year_changes):\n",
        "        with self.driver.session() as session:\n",
        "            improvements = 0\n",
        "            declines = 0\n",
        "\n",
        "            for change in year_changes:\n",
        "                if change['change_type'] == 'improvement':\n",
        "                    session.run(\"\"\"\n",
        "                        MATCH (c:Country {name: $country})\n",
        "                        MATCH (y1:Year {year: $from_year})\n",
        "                        MATCH (y2:Year {year: $to_year})\n",
        "                        MERGE (c)-[:IMPROVED_FROM {\n",
        "                            from_year: $from_year,\n",
        "                            to_year: $to_year,\n",
        "                            score_change: $score_change,\n",
        "                            rank_change: $rank_change\n",
        "                        }]->(y2)\n",
        "                    \"\"\",\n",
        "                        country=change['country'],\n",
        "                        from_year=int(change['from_year']),\n",
        "                        to_year=int(change['to_year']),\n",
        "                        score_change=float(change['score_change']),\n",
        "                        rank_change=int(change['rank_change'])\n",
        "                    )\n",
        "                    improvements += 1\n",
        "                elif change['change_type'] == 'decline':\n",
        "                    session.run(\"\"\"\n",
        "                        MATCH (c:Country {name: $country})\n",
        "                        MATCH (y1:Year {year: $from_year})\n",
        "                        MATCH (y2:Year {year: $to_year})\n",
        "                        MERGE (c)-[:DECLINED_FROM {\n",
        "                            from_year: $from_year,\n",
        "                            to_year: $to_year,\n",
        "                            score_change: $score_change,\n",
        "                            rank_change: $rank_change\n",
        "                        }]->(y2)\n",
        "                    \"\"\",\n",
        "                        country=change['country'],\n",
        "                        from_year=int(change['from_year']),\n",
        "                        to_year=int(change['to_year']),\n",
        "                        score_change=float(change['score_change']),\n",
        "                        rank_change=int(change['rank_change'])\n",
        "                    )\n",
        "                    declines += 1\n",
        "\n",
        "            print(f\"Created {improvements} IMPROVED_FROM and {declines} DECLINED_FROM relationships\")\n",
        "\n",
        "    def create_regional_comparison_relationships(self, standardized_data, regional_averages):\n",
        "        with self.driver.session() as session:\n",
        "            metric_mapping = {\n",
        "                'gdp_per_capita': 'GDP_per_Capita',\n",
        "                'social_support': 'Social_Support',\n",
        "                'healthy_life_expectancy': 'Healthy_Life_Expectancy',\n",
        "                'freedom_to_make_life_choices': 'Freedom_to_Make_Life_Choices',\n",
        "                'generosity': 'Generosity',\n",
        "                'perceptions_of_corruption': 'Perceptions_of_Corruption'\n",
        "            }\n",
        "\n",
        "            for year, df in standardized_data.items():\n",
        "                if 'region' not in df.columns:\n",
        "                    print(f\"Skipping regional comparisons for {year} - region mapping needed\")\n",
        "                    continue\n",
        "\n",
        "                above_count = 0\n",
        "                below_count = 0\n",
        "\n",
        "                for _, row in df.iterrows():\n",
        "                    if pd.notna(row.get('region')):\n",
        "                        region = row['region']\n",
        "                        country = row['country']\n",
        "\n",
        "                        for metric, metric_name in metric_mapping.items():\n",
        "                            if metric in row and region in regional_averages.get(year, {}):\n",
        "                                country_value = row[metric]\n",
        "                                regional_avg = regional_averages[year][region].get(metric, 0)\n",
        "\n",
        "                                if country_value > 0 and regional_avg > 0:\n",
        "                                    if country_value > regional_avg:\n",
        "                                        session.run(\"\"\"\n",
        "                                            MATCH (c:Country {name: $country})\n",
        "                                            MATCH (r:Region {name: $region})\n",
        "                                            MERGE (c)-[:ABOVE_REGIONAL_AVERAGE {\n",
        "                                                metric: $metric,\n",
        "                                                year: $year,\n",
        "                                                country_value: $country_value,\n",
        "                                                regional_average: $regional_avg,\n",
        "                                                difference: $diff\n",
        "                                            }]->(r)\n",
        "                                        \"\"\",\n",
        "                                            country=country,\n",
        "                                            region=region,\n",
        "                                            metric=metric_name,\n",
        "                                            year=int(year),\n",
        "                                            country_value=float(country_value),\n",
        "                                            regional_avg=float(regional_avg),\n",
        "                                            diff=float(country_value - regional_avg)\n",
        "                                        )\n",
        "                                        above_count += 1\n",
        "                                    else:\n",
        "                                        session.run(\"\"\"\n",
        "                                            MATCH (c:Country {name: $country})\n",
        "                                            MATCH (r:Region {name: $region})\n",
        "                                            MERGE (c)-[:BELOW_REGIONAL_AVERAGE {\n",
        "                                                metric: $metric,\n",
        "                                                year: $year,\n",
        "                                                country_value: $country_value,\n",
        "                                                regional_average: $regional_avg,\n",
        "                                                difference: $diff\n",
        "                                            }]->(r)\n",
        "                                        \"\"\",\n",
        "                                            country=country,\n",
        "                                            region=region,\n",
        "                                            metric=metric_name,\n",
        "                                            year=int(year),\n",
        "                                            country_value=float(country_value),\n",
        "                                            regional_avg=float(regional_avg),\n",
        "                                            diff=float(regional_avg - country_value)\n",
        "                                        )\n",
        "                                        below_count += 1\n",
        "\n",
        "                if above_count > 0 or below_count > 0:\n",
        "                    print(f\"Created {above_count} ABOVE and {below_count} BELOW regional comparison relationships for {year}\")\n",
        "\n",
        "    def build_complete_graph(self, processor, standardized_data, region_mapping,\n",
        "                           regional_averages, similar_countries, year_changes, leaders_laggards,\n",
        "                           include_similarity=True, include_regional_comparison=True):\n",
        "        print(\"Building Neo4j Graph Database...\")\n",
        "\n",
        "        print(\"1. Clearing database and creating constraints...\")\n",
        "        self.clear_database()\n",
        "        self.create_constraints_and_indexes()\n",
        "\n",
        "        print(\"2. Creating base nodes...\")\n",
        "        self.create_base_nodes(processor)\n",
        "\n",
        "        print(\"3. Creating core relationships...\")\n",
        "        self.create_country_region_relationships(region_mapping)\n",
        "        self.create_happiness_data_relationships(standardized_data)\n",
        "        self.create_tier_relationships(standardized_data)\n",
        "\n",
        "        print(\"4. Creating metric performance relationships...\")\n",
        "        self.create_metric_performance_relationships(leaders_laggards, standardized_data)\n",
        "\n",
        "        print(\"5. Creating temporal change relationships...\")\n",
        "        self.create_temporal_change_relationships(year_changes)\n",
        "\n",
        "        if include_similarity and similar_countries:\n",
        "            print(\"6. Creating similarity relationships...\")\n",
        "            self.create_similarity_relationships(similar_countries)\n",
        "        else:\n",
        "            print(\"6. Skipping similarity relationships (disabled or no data)\")\n",
        "\n",
        "        if include_regional_comparison:\n",
        "            print(\"7. Creating regional comparison relationships...\")\n",
        "            self.create_regional_comparison_relationships(standardized_data, regional_averages)\n",
        "        else:\n",
        "            print(\"7. Skipping regional comparison relationships (disabled)\")\n",
        "\n",
        "        print(\"Graph database build complete\")\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            node_count = session.run(\"MATCH (n) RETURN count(n) as count\").single()['count']\n",
        "            rel_count = session.run(\"MATCH ()-[r]->() RETURN count(r) as count\").single()['count']\n",
        "            print(f\"Final Stats: {node_count} nodes, {rel_count} relationships\")"
      ],
      "metadata": {
        "id": "mF7JEIrJUO2U"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = HappinessGraphBuilder(\n",
        "    uri=\"neo4j+s://d9b35a07.databases.neo4j.io\",                # Neo4j URI\n",
        "    username=\"neo4j\",                                           # Username\n",
        "    password=\"VT0pUGstL96Jmpq_pnCtzF-WKc-EE9b2lEJ5VNrq7og\"      # Password\n",
        ")"
      ],
      "metadata": {
        "id": "_9XjBahQU7l-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.build_complete_graph(\n",
        "    processor=processor,\n",
        "    standardized_data=standardized_data,\n",
        "    region_mapping=region_mapping,\n",
        "    regional_averages=regional_averages,\n",
        "    similar_countries=similar_countries,\n",
        "    year_changes=year_changes,\n",
        "    leaders_laggards=leaders_laggards,\n",
        "    include_similarity=False,\n",
        "    include_regional_comparison=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9_ysUmLVMxD",
        "outputId": "42e78231-2e95-4ad7-c772-d7cde614541e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Neo4j Graph Database...\n",
            "1. Clearing database and creating constraints...\n",
            "Database cleared\n",
            "✓ Created: CONSTRAINT country_name\n",
            "✓ Created: CONSTRAINT region_name\n",
            "✓ Created: CONSTRAINT year_value\n",
            "✓ Created: CONSTRAINT metric_name\n",
            "✓ Created: CONSTRAINT tier_name\n",
            "✓ Created: CONSTRAINT level_name\n",
            "✓ Created: INDEX country_happiness_score\n",
            "✓ Created: INDEX country_happiness_rank\n",
            "2. Creating base nodes...\n",
            "Created 170 Country nodes\n",
            "Created 10 Region nodes\n",
            "Created 5 Year nodes\n",
            "Created 6 MetricCategory nodes\n",
            "Created 5 HappinessTier nodes\n",
            "Created 4 PerformanceLevel nodes\n",
            "3. Creating core relationships...\n",
            "Created 164 BELONGS_TO relationships\n",
            "Created 158 HAS_HAPPINESS_DATA relationships for 2015\n",
            "Created 157 HAS_HAPPINESS_DATA relationships for 2016\n",
            "Created 155 HAS_HAPPINESS_DATA relationships for 2017\n",
            "Created 156 HAS_HAPPINESS_DATA relationships for 2018\n",
            "Created 156 HAS_HAPPINESS_DATA relationships for 2019\n",
            "Created tier relationships for 2015\n",
            "Created tier relationships for 2016\n",
            "Created tier relationships for 2017\n",
            "Created tier relationships for 2018\n",
            "Created tier relationships for 2019\n",
            "4. Creating metric performance relationships...\n",
            "Created EXCELS_IN relationships for 2015\n",
            "Created EXCELS_IN relationships for 2016\n",
            "Created EXCELS_IN relationships for 2017\n",
            "Created EXCELS_IN relationships for 2018\n",
            "Created EXCELS_IN relationships for 2019\n",
            "Created STRUGGLES_WITH relationships for 2015\n",
            "Created STRUGGLES_WITH relationships for 2016\n",
            "Created STRUGGLES_WITH relationships for 2017\n",
            "Created STRUGGLES_WITH relationships for 2018\n",
            "Created STRUGGLES_WITH relationships for 2019\n",
            "5. Creating temporal change relationships...\n",
            "Created 162 IMPROVED_FROM and 127 DECLINED_FROM relationships\n",
            "6. Skipping similarity relationships (disabled or no data)\n",
            "7. Creating regional comparison relationships...\n",
            "Created 466 ABOVE and 476 BELOW regional comparison relationships for 2015\n",
            "Created 469 ABOVE and 467 BELOW regional comparison relationships for 2016\n",
            "Created 462 ABOVE and 450 BELOW regional comparison relationships for 2017\n",
            "Created 469 ABOVE and 447 BELOW regional comparison relationships for 2018\n",
            "Created 465 ABOVE and 441 BELOW regional comparison relationships for 2019\n",
            "Graph database build complete\n",
            "Final Stats: 200 nodes, 7529 relationships\n"
          ]
        }
      ]
    }
  ]
}